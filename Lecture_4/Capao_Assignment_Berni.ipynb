{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c40556a8-02d2-487a-8720-5d3a4fed3312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import logsumexp\n",
    "\n",
    "class StochasticBernoulliMixture:\n",
    "    def __init__(self, n_components, max_iter, batch_size, random_state=None):\n",
    "        self.n_components = n_components\n",
    "        self.max_iter = max_iter\n",
    "        self.batch_size = batch_size\n",
    "        self.random_state = random_state\n",
    "        self.rng = np.random.default_rng(self.random_state) if self.random_state else np.random.default_rng()\n",
    "        \n",
    "        # Initialize old parameters\n",
    "        self.old_mu = None\n",
    "        self.old_pi = None\n",
    "        self.old_gamma = None\n",
    "    \n",
    "    def fit(self, x_binary):\n",
    "        self.x = x_binary\n",
    "        self.init_params()\n",
    "        log_bernoullis = self.get_log_bernoullis(self.x)\n",
    "        self.old_logL = self.get_log_likelihood(log_bernoullis)\n",
    "        for step in range(self.max_iter):\n",
    "            if step > 0:\n",
    "                self.old_logL = self.logL\n",
    "            # Stochastic E-step and M-step\n",
    "            for _ in range(self.batch_size):\n",
    "                batch_indices = self.rng.choice(len(self.x), size=self.batch_size, replace=False)\n",
    "                x_batch = self.x[batch_indices]\n",
    "                log_bernoullis_batch = self.get_log_bernoullis(x_batch)\n",
    "                self.gamma = self.get_responsibilities(log_bernoullis_batch)\n",
    "                self.get_Neff()\n",
    "                self.get_mu(x_batch)\n",
    "                self.get_pi()\n",
    "            # Compute new log_likelihood:\n",
    "            log_bernoullis = self.get_log_bernoullis(self.x)\n",
    "            self.logL = self.get_log_likelihood(log_bernoullis)\n",
    "            if np.isnan(self.logL):\n",
    "                self.reset_params()\n",
    "                print(self.logL)\n",
    "                break\n",
    "\n",
    "    def reset_params(self):\n",
    "        if self.old_mu is not None:\n",
    "            self.mu = self.old_mu.copy()\n",
    "        if self.old_pi is not None:\n",
    "            self.pi = self.old_pi.copy()\n",
    "        if self.old_gamma is not None:\n",
    "            self.gamma = self.old_gamma.copy()\n",
    "        self.get_Neff()\n",
    "        log_bernoullis = self.get_log_bernoullis(self.x)\n",
    "        self.logL = self.get_log_likelihood(log_bernoullis)\n",
    "        \n",
    "    def remember_params(self):\n",
    "        self.old_mu = self.mu.copy()\n",
    "        self.old_pi = self.pi.copy()\n",
    "        self.old_gamma = self.gamma.copy()\n",
    "    \n",
    "    def init_params(self):\n",
    "        self.n_samples = self.x.shape[0]\n",
    "        self.n_features = self.x.shape[1]\n",
    "        self.pi = 1/self.n_components * np.ones(self.n_components)\n",
    "        self.mu = self.rng.uniform(low=0.25, high=0.75, size=(self.n_components, self.n_features))\n",
    "        self.normalize_mu()\n",
    "    \n",
    "    def normalize_mu(self):\n",
    "        sum_over_features = np.sum(self.mu, axis=1)\n",
    "        for k in range(self.n_components):\n",
    "            self.mu[k,:] /= sum_over_features[k]\n",
    "            \n",
    "    def get_responsibilities(self, log_bernoullis):\n",
    "        gamma = np.zeros(shape=(log_bernoullis.shape[0], self.n_components))\n",
    "        Z =  logsumexp(np.log(self.pi[None,:]) + log_bernoullis, axis=1)\n",
    "        for k in range(self.n_components):\n",
    "            gamma[:, k] = np.exp(np.log(self.pi[k]) + log_bernoullis[:,k] - Z)\n",
    "        return gamma\n",
    "        \n",
    "    def get_log_bernoullis(self, x):\n",
    "        log_bernoullis = self.get_save_single(x, self.mu)\n",
    "        log_bernoullis += self.get_save_single(1-x, 1-self.mu)\n",
    "        return log_bernoullis\n",
    "    \n",
    "    def get_save_single(self, x, mu):\n",
    "        mu_place = np.where(np.max(mu, axis=0) <= 1e-15, 1e-15, mu)\n",
    "        return np.tensordot(x, np.log(mu_place), (1,1))\n",
    "        \n",
    "    def get_Neff(self):\n",
    "        self.Neff = np.sum(self.gamma, axis=0)\n",
    "    \n",
    "    def get_mu(self, x_batch):\n",
    "        self.mu = np.einsum('ik,ij -> kj', self.gamma, x_batch) / self.Neff[:,None]\n",
    "\n",
    "        \n",
    "    def get_pi(self):\n",
    "        self.pi = self.Neff / self.n_samples\n",
    "    \n",
    "    def predict(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        gamma = self.get_responsibilities(log_bernoullis)\n",
    "        return np.argmax(gamma, axis=1)\n",
    "        \n",
    "    def get_sample_log_likelihood(self, log_bernoullis):\n",
    "        return logsumexp(np.log(self.pi[None,:]) + log_bernoullis, axis=1)\n",
    "    \n",
    "    def get_log_likelihood(self, log_bernoullis):\n",
    "        return np.mean(self.get_sample_log_likelihood(log_bernoullis))\n",
    "        \n",
    "    def score(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        return self.get_log_likelihood(log_bernoullis)\n",
    "    \n",
    "    def score_samples(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        return self.get_sample_log_likelihood(log_bernoullis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd4513bc-a394-49f4-bf1c-53cab7e853bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "soybean_large = fetch_ucirepo(id=90) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = soybean_large.data.features \n",
    "y = soybean_large.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fbd2279-be82-43d3-88cc-b1bcbbb733fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StochasticBernoulliMixture' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m  \u001b[38;5;66;03m# Size of mini-batch\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Initialize the StochasticBernoulliMixture model\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m stochastic_bmm \u001b[38;5;241m=\u001b[39m \u001b[43mStochasticBernoulliMixture\u001b[49m(n_components\u001b[38;5;241m=\u001b[39mn_components, max_iter\u001b[38;5;241m=\u001b[39mmax_iter, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Fit the model to the binary encoded data\u001b[39;00m\n\u001b[0;32m     23\u001b[0m stochastic_bmm\u001b[38;5;241m.\u001b[39mfit(X_encoded)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StochasticBernoulliMixture' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Preprocessing\n",
    "# Handling missing values\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "X_encoded = encoder.fit_transform(X_imputed).toarray()  # Convert to dense array\n",
    "\n",
    "# Perform clustering\n",
    "n_components = 3  # Number of clusters\n",
    "max_iter = 100  # Maximum number of iterations\n",
    "batch_size = 50  # Size of mini-batch\n",
    "\n",
    "# Initialize the StochasticBernoulliMixture model\n",
    "stochastic_bmm = StochasticBernoulliMixture(n_components=n_components, max_iter=max_iter, batch_size=batch_size)\n",
    "\n",
    "# Fit the model to the binary encoded data\n",
    "stochastic_bmm.fit(X_encoded)\n",
    "\n",
    "# Extract cluster assignments\n",
    "cluster_assignments = stochastic_bmm.predict(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3668ee1a-d308-4b07-9f40-40e65bad5fd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Reduce the dimensionality of the data to 2 dimensions using PCA\u001b[39;00m\n\u001b[0;32m      5\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m X_pca \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_encoded\u001b[49m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Plot the clustered data\u001b[39;00m\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_encoded' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce the dimensionality of the data to 2 dimensions using PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_encoded)\n",
    "\n",
    "# Plot the clustered data\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_assignments, cmap='rocket', s=50, alpha=0.5)\n",
    "plt.title('Clustering Results (PCA)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58919899-4734-4b0e-83fc-a0ee2cd2f2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 47, cost: 2386.0\n",
      "Run 1, iteration: 2/100, moves: 8, cost: 2386.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 113, cost: 2436.0\n",
      "Run 2, iteration: 2/100, moves: 28, cost: 2395.0\n",
      "Run 2, iteration: 3/100, moves: 3, cost: 2395.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 109, cost: 2406.0\n",
      "Run 3, iteration: 2/100, moves: 25, cost: 2378.0\n",
      "Run 3, iteration: 3/100, moves: 19, cost: 2355.0\n",
      "Run 3, iteration: 4/100, moves: 7, cost: 2352.0\n",
      "Run 3, iteration: 5/100, moves: 4, cost: 2348.0\n",
      "Run 3, iteration: 6/100, moves: 0, cost: 2348.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 35, cost: 2349.0\n",
      "Run 4, iteration: 2/100, moves: 18, cost: 2337.0\n",
      "Run 4, iteration: 3/100, moves: 3, cost: 2337.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 56, cost: 2438.0\n",
      "Best run was number 4\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cluster_assignments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m km_cluster_assignments \u001b[38;5;241m=\u001b[39m km\u001b[38;5;241m.\u001b[39mlabels_\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Evaluate performance using various metrics\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m ari \u001b[38;5;241m=\u001b[39m adjusted_rand_score(\u001b[43mcluster_assignments\u001b[49m, km_cluster_assignments)\n\u001b[0;32m     14\u001b[0m nmi \u001b[38;5;241m=\u001b[39m normalized_mutual_info_score(cluster_assignments, km_cluster_assignments)\n\u001b[0;32m     15\u001b[0m fmi \u001b[38;5;241m=\u001b[39m fowlkes_mallows_score(cluster_assignments, km_cluster_assignments)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cluster_assignments' is not defined"
     ]
    }
   ],
   "source": [
    "# KMODES ALGO\n",
    "from kmodes.kmodes import KModes\n",
    "from sklearn.metrics.cluster import adjusted_rand_score, normalized_mutual_info_score, fowlkes_mallows_score\n",
    "\n",
    "# Initialize and fit the KModes model\n",
    "km = KModes(n_clusters=n_components, init='Huang', n_init=5, verbose=1, random_state=42)\n",
    "km.fit(X_imputed)\n",
    "\n",
    "# Get cluster assignments from KModes\n",
    "km_cluster_assignments = km.labels_\n",
    "\n",
    "# Evaluate performance using various metrics\n",
    "ari = adjusted_rand_score(cluster_assignments, km_cluster_assignments)\n",
    "nmi = normalized_mutual_info_score(cluster_assignments, km_cluster_assignments)\n",
    "fmi = fowlkes_mallows_score(cluster_assignments, km_cluster_assignments)\n",
    "\n",
    "print(\"Adjusted Rand Index (ARI):\", ari)\n",
    "print(\"Normalized Mutual Information Score (NMI):\", nmi)\n",
    "print(\"Folkes-Mallows Index (FMI):\", fmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52b32e8c-13f7-4d79-937b-1bd34e7c6a18",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cluster_assignments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m km_fmi \u001b[38;5;241m=\u001b[39m fowlkes_mallows_score(y_flat, km_cluster_assignments)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Evaluate performance of Stochastic Bernoulli Mixture model\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m sbm_ari \u001b[38;5;241m=\u001b[39m adjusted_rand_score(y_flat, \u001b[43mcluster_assignments\u001b[49m)\n\u001b[0;32m     21\u001b[0m sbm_nmi \u001b[38;5;241m=\u001b[39m normalized_mutual_info_score(y_flat, cluster_assignments)\n\u001b[0;32m     22\u001b[0m sbm_fmi \u001b[38;5;241m=\u001b[39m fowlkes_mallows_score(y_flat, cluster_assignments)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cluster_assignments' is not defined"
     ]
    }
   ],
   "source": [
    "from kmodes.kmodes import KModes\n",
    "from sklearn.metrics.cluster import adjusted_rand_score, normalized_mutual_info_score, fowlkes_mallows_score\n",
    "\n",
    "# Fit the K-Modes model\n",
    "km = KModes(n_clusters=n_components, init='Huang', n_init=5, verbose=0, random_state=42)\n",
    "km.fit(X_imputed)\n",
    "\n",
    "# Get cluster assignments from K-Modes\n",
    "km_cluster_assignments = km.labels_\n",
    "\n",
    "# Flatten the true cluster assignments\n",
    "y_flat = y.values.ravel()\n",
    "\n",
    "# Evaluate performance of K-Modes\n",
    "km_ari = adjusted_rand_score(y_flat, km_cluster_assignments)\n",
    "km_nmi = normalized_mutual_info_score(y_flat, km_cluster_assignments)\n",
    "km_fmi = fowlkes_mallows_score(y_flat, km_cluster_assignments)\n",
    "\n",
    "# Evaluate performance of Stochastic Bernoulli Mixture model\n",
    "sbm_ari = adjusted_rand_score(y_flat, cluster_assignments)\n",
    "sbm_nmi = normalized_mutual_info_score(y_flat, cluster_assignments)\n",
    "sbm_fmi = fowlkes_mallows_score(y_flat, cluster_assignments)\n",
    "\n",
    "\n",
    "print(\"Performance Comparison:\")\n",
    "print(\"K-Modes - Adjusted Rand Index (ARI):\", km_ari)\n",
    "print(\"K-Modes - Normalized Mutual Information Score (NMI):\", km_nmi)\n",
    "print(\"K-Modes - Folkes-Mallows Index (FMI):\", km_fmi)\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Stochastic Bernoulli Mixture - Adjusted Rand Index (ARI):\", sbm_ari)\n",
    "print(\"Stochastic Bernoulli Mixture - Normalized Mutual Information Score (NMI):\", sbm_nmi)\n",
    "print(\"Stochastic Bernoulli Mixture - Folkes-Mallows Index (FMI):\", sbm_fmi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01ce20-86d7-4514-906e-ae5d9162be48",
   "metadata": {},
   "source": [
    "$\\textbf{Report Summary}$\n",
    "- These are the performances of K-Modes and Stochastic Bernoulli Mixture clustering algorithms using three evaluation metrics: Adjusted Rand Index (ARI), Normalized Mutual Information Score (NMI), and Folkes-Mallows Index (FMI). These metrics indicate how well the generated clusters align with the actual clustering.\n",
    "\n",
    "$\\textbf{Performance Metrics:}$\n",
    "1. K-Modes:\n",
    "   - ARI: 0.166\n",
    "   - NMI: 0.402\n",
    "   - FMI: 0.379\n",
    "\n",
    "2. Stochastic Bernoulli Mixture:\n",
    "   - ARI: 0.0\n",
    "   - NMI: 0.0\n",
    "   - FMI: 0.290"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
